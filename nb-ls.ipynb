{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data '/Users/yufang/Desktop/Netflix Project/combined_data_1.txt' to 'movies_rating1.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_file_path = '/Users/yufang/Desktop/Netflix Project/combined_data_1.txt' \n",
    "output_file_path = 'movies_rating1.csv'  \n",
    "\n",
    "data = []\n",
    "current_movie_id = None\n",
    "\n",
    "# Read input file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.endswith(':'):\n",
    "            current_movie_id = line[:-1]  # get movie id\n",
    "        else:\n",
    "            user_id, rating, date = line.split(',')\n",
    "            data.append([current_movie_id, user_id, rating, date])\n",
    "\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['movie_id', 'user_id', 'rating', 'date'])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Write data '{input_file_path}' to '{output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data '/Users/yufang/Desktop/Netflix Project/combined_data_2.txt' to 'movies_rating2.csv\n"
     ]
    }
   ],
   "source": [
    "input_file_path = '/Users/yufang/Desktop/Netflix Project/combined_data_2.txt' \n",
    "output_file_path = 'movies_rating2.csv'  \n",
    "\n",
    "data = []\n",
    "current_movie_id = None\n",
    "\n",
    "# Read input file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.endswith(':'):\n",
    "            current_movie_id = line[:-1]  # get movie id\n",
    "        else:\n",
    "            user_id, rating, date = line.split(',')\n",
    "            data.append([current_movie_id, user_id, rating, date])\n",
    "\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['movie_id', 'user_id', 'rating', 'date'])\n",
    "    writer.writerows(data)\n",
    "print(f\"Write data '{input_file_path}' to '{output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data '/Users/yufang/Desktop/Netflix Project/combined_data_3.txt' to 'movies_rating3.csv\n"
     ]
    }
   ],
   "source": [
    "input_file_path = '/Users/yufang/Desktop/Netflix Project/combined_data_3.txt' \n",
    "output_file_path = 'movies_rating3.csv'  \n",
    "\n",
    "data = []\n",
    "current_movie_id = None\n",
    "\n",
    "# Read input file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.endswith(':'):\n",
    "            current_movie_id = line[:-1]  # get movie id\n",
    "        else:\n",
    "            user_id, rating, date = line.split(',')\n",
    "            data.append([current_movie_id, user_id, rating, date])\n",
    "\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['movie_id', 'user_id', 'rating', 'date'])\n",
    "    writer.writerows(data)\n",
    "    \n",
    "print(f\"Write data '{input_file_path}' to '{output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data '/Users/yufang/Desktop/Netflix Project/combined_data_4.txt' to 'movies_rating4.csv\n"
     ]
    }
   ],
   "source": [
    "input_file_path = '/Users/yufang/Desktop/Netflix Project/combined_data_4.txt' \n",
    "output_file_path = 'movies_rating4.csv'  \n",
    "\n",
    "data = []\n",
    "current_movie_id = None\n",
    "\n",
    "# Read input file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.endswith(':'):\n",
    "            current_movie_id = line[:-1]  # get movie id\n",
    "        else:\n",
    "            user_id, rating, date = line.split(',')\n",
    "            data.append([current_movie_id, user_id, rating, date])\n",
    "\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['movie_id', 'user_id', 'rating', 'date'])\n",
    "    writer.writerows(data)\n",
    "print(f\"Write data '{input_file_path}' to '{output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = pd.read_csv('movie_titles.csv', header=None,delimiter='\\t', names=['Combined'], encoding='latin1')\n",
    "movie_title[['ID', 'Year', 'Title']] = movie_title['Combined'].str.split(',', n=2, expand=True)\n",
    "movie_title = movie_title.drop(columns=['Combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating1 = pd.read_csv('movies_rating1.csv')\n",
    "movie_rating2 = pd.read_csv('movies_rating2.csv')\n",
    "movie_rating3 = pd.read_csv('movies_rating3.csv')\n",
    "movie_rating4 = pd.read_csv('movies_rating4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = pd.concat([movie_rating1, movie_rating2, movie_rating3, movie_rating4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating['date'] = pd.to_datetime(movie_rating['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100480507\n"
     ]
    }
   ],
   "source": [
    "movie_rating.sort_values(by='date', inplace=True)\n",
    "print(len(movie_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100480507\n"
     ]
    }
   ],
   "source": [
    "movie_title['ID'] = movie_title['ID'].astype('int64')\n",
    "movie = movie_rating.merge(movie_title, left_on='movie_id', right_on='ID', how='left')\n",
    "movie = movie.drop(columns=['ID'])\n",
    "print(len(movie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000\n"
     ]
    }
   ],
   "source": [
    "movie_slice = movie.iloc[-180000:] # get last 100000 entries since it's most relevant\n",
    "print(len(movie_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100460507</th>\n",
       "      <td>16445</td>\n",
       "      <td>1250138</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2003</td>\n",
       "      <td>House of 1,000 Corpses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460508</th>\n",
       "      <td>6850</td>\n",
       "      <td>714682</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2005</td>\n",
       "      <td>Lords of Dogtown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460509</th>\n",
       "      <td>3441</td>\n",
       "      <td>859907</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2005</td>\n",
       "      <td>Kicking &amp; Screaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460510</th>\n",
       "      <td>10748</td>\n",
       "      <td>2373473</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>1987</td>\n",
       "      <td>Hamburger Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460511</th>\n",
       "      <td>5496</td>\n",
       "      <td>1678873</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2004</td>\n",
       "      <td>I, Robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480502</th>\n",
       "      <td>8993</td>\n",
       "      <td>2183787</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2005</td>\n",
       "      <td>Family Guy Presents: Stewie Griffin: The Untol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480503</th>\n",
       "      <td>7430</td>\n",
       "      <td>258170</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2001</td>\n",
       "      <td>Six Feet Under: Season 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480504</th>\n",
       "      <td>8467</td>\n",
       "      <td>1534359</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>1996</td>\n",
       "      <td>Eraser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480505</th>\n",
       "      <td>10168</td>\n",
       "      <td>2543295</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2003</td>\n",
       "      <td>The League of Extraordinary Gentlemen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480506</th>\n",
       "      <td>4736</td>\n",
       "      <td>1346243</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>1981</td>\n",
       "      <td>Chariots of Fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_id  user_id  rating       date  Year  \\\n",
       "100460507     16445  1250138       2 2005-12-31  2003   \n",
       "100460508      6850   714682       1 2005-12-31  2005   \n",
       "100460509      3441   859907       2 2005-12-31  2005   \n",
       "100460510     10748  2373473       3 2005-12-31  1987   \n",
       "100460511      5496  1678873       2 2005-12-31  2004   \n",
       "...             ...      ...     ...        ...   ...   \n",
       "100480502      8993  2183787       4 2005-12-31  2005   \n",
       "100480503      7430   258170       4 2005-12-31  2001   \n",
       "100480504      8467  1534359       5 2005-12-31  1996   \n",
       "100480505     10168  2543295       2 2005-12-31  2003   \n",
       "100480506      4736  1346243       5 2005-12-31  1981   \n",
       "\n",
       "                                                       Title  \n",
       "100460507                             House of 1,000 Corpses  \n",
       "100460508                                   Lords of Dogtown  \n",
       "100460509                                Kicking & Screaming  \n",
       "100460510                                     Hamburger Hill  \n",
       "100460511                                           I, Robot  \n",
       "...                                                      ...  \n",
       "100480502  Family Guy Presents: Stewie Griffin: The Untol...  \n",
       "100480503                           Six Feet Under: Season 1  \n",
       "100480504                                             Eraser  \n",
       "100480505              The League of Extraordinary Gentlemen  \n",
       "100480506                                   Chariots of Fire  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = movie_slice[160000:]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100300507</th>\n",
       "      <td>17147</td>\n",
       "      <td>427460</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-29</td>\n",
       "      <td>1996</td>\n",
       "      <td>She's the One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100300508</th>\n",
       "      <td>4353</td>\n",
       "      <td>1605111</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-12-29</td>\n",
       "      <td>2002</td>\n",
       "      <td>Curb Your Enthusiasm: Season 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100300509</th>\n",
       "      <td>3923</td>\n",
       "      <td>13949</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-12-29</td>\n",
       "      <td>1997</td>\n",
       "      <td>Beverly Hills Ninja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100300510</th>\n",
       "      <td>6874</td>\n",
       "      <td>200779</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-12-29</td>\n",
       "      <td>2003</td>\n",
       "      <td>The Cooler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100300511</th>\n",
       "      <td>12582</td>\n",
       "      <td>851475</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-29</td>\n",
       "      <td>2003</td>\n",
       "      <td>Mystic River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460502</th>\n",
       "      <td>13629</td>\n",
       "      <td>1318034</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>1951</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460503</th>\n",
       "      <td>17324</td>\n",
       "      <td>1719503</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2005</td>\n",
       "      <td>Hitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460504</th>\n",
       "      <td>17324</td>\n",
       "      <td>22846</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2005</td>\n",
       "      <td>Hitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460505</th>\n",
       "      <td>3860</td>\n",
       "      <td>1799620</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2003</td>\n",
       "      <td>Bruce Almighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100460506</th>\n",
       "      <td>2153</td>\n",
       "      <td>1635209</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>1993</td>\n",
       "      <td>Free Willy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_id  user_id  rating       date  Year  \\\n",
       "100300507     17147   427460       4 2005-12-29  1996   \n",
       "100300508      4353  1605111       5 2005-12-29  2002   \n",
       "100300509      3923    13949       3 2005-12-29  1997   \n",
       "100300510      6874   200779       3 2005-12-29  2003   \n",
       "100300511     12582   851475       4 2005-12-29  2003   \n",
       "...             ...      ...     ...        ...   ...   \n",
       "100460502     13629  1318034       4 2005-12-31  1951   \n",
       "100460503     17324  1719503       4 2005-12-31  2005   \n",
       "100460504     17324    22846       5 2005-12-31  2005   \n",
       "100460505      3860  1799620       2 2005-12-31  2003   \n",
       "100460506      2153  1635209       5 2005-12-31  1993   \n",
       "\n",
       "                                    Title  \n",
       "100300507                   She's the One  \n",
       "100300508  Curb Your Enthusiasm: Season 3  \n",
       "100300509             Beverly Hills Ninja  \n",
       "100300510                      The Cooler  \n",
       "100300511                    Mystic River  \n",
       "...                                   ...  \n",
       "100460502             Alice in Wonderland  \n",
       "100460503                           Hitch  \n",
       "100460504                           Hitch  \n",
       "100460505                  Bruce Almighty  \n",
       "100460506                      Free Willy  \n",
       "\n",
       "[160000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = movie_slice[:160000]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "individual_train, ensemble_train = train_test_split(train, test_size=0.5, random_state=42)\n",
    "print(len(individual_train))\n",
    "print(len(ensemble_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# Create train_nb_ls and test_nb_ls for model fitting\n",
    "X_train_nb_ls = individual_train[['user_id', 'movie_id']].rename(columns={ 'movie_id': 'item_id'})\n",
    "y_train_nb_ls = individual_train['rating']\n",
    "train_nb_ls = X_train_nb_ls.copy()\n",
    "train_nb_ls['rating'] = y_train_nb_ls\n",
    "test_nb_ls = test.rename(columns={'movie_id': 'item_id'})\n",
    "print(len(train_nb_ls))\n",
    "print(len(test_nb_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement NB-LS Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborhoodLS:\n",
    "    def __init__(self, alpha=1.0, lambda_=1.0, top_n=6000):\n",
    "        self.alpha = alpha  # Amplification factor\n",
    "        self.lambda_ = lambda_  # Regularization term\n",
    "        self.top_n = top_n  # top_n items with most ratings for calculating similarities\n",
    "        self.similarity_matrix_ = None\n",
    "        self.global_mean = None\n",
    "\n",
    "    def fit(self, ratings):\n",
    "        self.ratings = ratings\n",
    "        self.global_mean = ratings['rating'].mean() # Compute global mean\n",
    "\n",
    "        self.item_means = ratings.groupby('item_id')['rating'].mean().to_dict() # Compute item mean\n",
    "        self.user_means = ratings.groupby('user_id')['rating'].mean().to_dict() # Compute user mean\n",
    "        \n",
    "        # Get the top N most-rated items\n",
    "        self.top_items = self.get_item_most_rating(ratings, self.top_n)\n",
    "\n",
    "        user_index = ratings['user_id'].unique()\n",
    "        item_index = ratings['item_id'].unique()\n",
    "        self.user_mapping = {user_id: i for i, user_id in enumerate(user_index)}  # Map user_id to indices\n",
    "        self.item_mapping = {item_id: i for i, item_id in enumerate(item_index)}  # Map item_id to indices\n",
    "\n",
    "        # Create sparse matrix\n",
    "        self.user_item_matrix = csr_matrix(\n",
    "            (ratings['rating'], (ratings['user_id'].map(self.user_mapping), ratings['item_id'].map(self.item_mapping))),\n",
    "            shape=(len(user_index), len(item_index))\n",
    "        )\n",
    "\n",
    "        # Create similarity matrix\n",
    "        self.similarity_matrix_ = self._compute_similarity()\n",
    "        return self\n",
    "\n",
    "    def get_item_most_rating(self, ratings, top_n):\n",
    "        item_counts = ratings.groupby('item_id').size() # Count how many item in the ratings DataFrame\n",
    "        top_items = item_counts.nlargest(top_n).index.tolist() # Get the top_n items with most ratings\n",
    "        return top_items\n",
    "\n",
    "    def _compute_similarity(self):\n",
    "        top_item_indices = [self.item_mapping[item_id] for item_id in self.top_items if item_id in self.item_mapping]\n",
    "        num_items = len(top_item_indices) # Only calculate similarity between 6000 items with most ratings\n",
    "        similarity_matrix = np.zeros((len(self.item_mapping), len(self.item_mapping))) # Initialize similarity matrix\n",
    "\n",
    "        # Create matrix B based on T_u^(-0.5)\n",
    "        B = (self.user_item_matrix != 0).astype(float)\n",
    "        item_counts = np.array(B.sum(axis=0)).flatten()\n",
    "        for i, count in enumerate(item_counts):\n",
    "            if count > 0:\n",
    "                B[:, i] /= np.sqrt(count)\n",
    "\n",
    "        B_top_n = B[:, top_item_indices] # Consider only top_n items with most ratings\n",
    "\n",
    "        # Compute (B^TB + lambda * I)^-1 for top_n items\n",
    "        B_T_B = B_top_n.T @ B_top_n\n",
    "        identity = np.identity(num_items)\n",
    "        inverse_term = np.linalg.inv(B_T_B + self.lambda_ * identity)\n",
    "\n",
    "        # Compute similarity\n",
    "        for i in top_item_indices: # Loop over top_n items with most ratings\n",
    "            item_ratings = self.user_item_matrix[:, i].toarray().flatten()\n",
    "            rated_by_users = np.where(item_ratings != 0)[0]\n",
    "\n",
    "            # Create B_i and r_i for the specific item i\n",
    "            B_i = B[rated_by_users, :][:, top_item_indices]\n",
    "            r_i = item_ratings[rated_by_users].reshape(-1, 1)\n",
    "\n",
    "            # Compute similarity vector s_i\n",
    "            B_i_T_r_i = B_i.T @ r_i\n",
    "            s_i = self.alpha * (inverse_term @ B_i_T_r_i).flatten()\n",
    "            similarity_matrix[i, top_item_indices] = s_i\n",
    "\n",
    "        return similarity_matrix\n",
    "\n",
    "    def baseline_prediction(self, user_id, item_id):\n",
    "        user_avg = self.user_means.get(user_id, self.global_mean) # Compute user average\n",
    "        item_avg = self.item_means.get(item_id, self.global_mean) # Compute item average\n",
    "        baseline = 0.5 * user_avg + 0.5 * item_avg # (50% user average, 50% item average)\n",
    "        return baseline\n",
    "\n",
    "    def predict_pair(self, user_id, item_id):\n",
    "        # Use baseline prediction for unknown users and items\n",
    "        if user_id not in self.user_mapping or item_id not in self.item_mapping:\n",
    "            return self.baseline_prediction(user_id, item_id)\n",
    "\n",
    "        user_idx = self.user_mapping[user_id]\n",
    "        item_idx = self.item_mapping[item_id]\n",
    "\n",
    "        # Use baseline prediction for items not in top_n most rated items\n",
    "        if item_idx not in self.similarity_matrix_:\n",
    "            return self.baseline_prediction(user_id, item_id)\n",
    "\n",
    "        # Compute prediction for items with known similarities\n",
    "        user_ratings = self.user_item_matrix[user_idx].toarray().flatten()\n",
    "        similarities = self.similarity_matrix_[item_idx]\n",
    "\n",
    "        # Use baseline prediction for items with 0 ratings\n",
    "        rated_items = user_ratings > 0\n",
    "        if np.sum(rated_items) == 0:\n",
    "            return self.baseline_prediction(user_id, item_id)\n",
    "\n",
    "        # Compute the sum of dot product between interpolation weight and subprediction\n",
    "        interpolation_subprediction_sum = np.dot(similarities[rated_items], user_ratings[rated_items])\n",
    "        \n",
    "        # Use sim_sum as a regularization term\n",
    "        sim_sum = np.sum(np.abs(similarities[rated_items]))\n",
    "\n",
    "        if sim_sum > 0:\n",
    "            predicted_rating = interpolation_subprediction_sum / sim_sum\n",
    "        else:\n",
    "            predicted_rating = self.baseline_prediction(user_id, item_id)\n",
    "            \n",
    "        return predicted_rating # Prediction of r_ui\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.predict_pair(row['user_id'], row['item_id']) for _, row in X.iterrows()]\n",
    "\n",
    "    def compute_rmse(self, X):\n",
    "        predictions = self.predict(X)\n",
    "        true_ratings = X['rating'].values # True ratings from the testing dataset\n",
    "        rmse = np.sqrt(mean_squared_error(true_ratings, predictions))\n",
    "        return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.958317622104055\n"
     ]
    }
   ],
   "source": [
    "# RMSE with 100000 entries, 7min\n",
    "model_nb_ls = NeighborhoodLS(alpha=3, lambda_=4000, top_n=6000)\n",
    "model_nb_ls.fit(train_nb_ls)\n",
    "rmse_nb_ls = model_nb_ls.compute_rmse(test_nb_ls)\n",
    "print(f\"Test RMSE: {rmse_nb_ls:.15f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "X_train_nb_ls_ensemble = ensemble_train[['user_id', 'movie_id']].rename(columns={ 'movie_id': 'item_id'})\n",
    "y_train_nb_ls_ensemble = ensemble_train['rating']\n",
    "train_nb_ls_ensemble = X_train_nb_ls_ensemble.copy()\n",
    "train_nb_ls_ensemble['rating'] = y_train_nb_ls_ensemble\n",
    "test_nb_ls_ensemble = test.rename(columns={'movie_id': 'item_id'})\n",
    "print(len(train_nb_ls_ensemble))\n",
    "print(len(test_nb_ls_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_nb_ls.predict(train_nb_ls_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array = np.array(pred)\n",
    "train_pred = pd.DataFrame(pred_array, columns=['predicted_rating_nb_ls'])\n",
    "train_pred.to_csv('predicted_rating_nb_ls_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model_nb_ls.predict(test_nb_ls_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array_test = np.array(pred_test)\n",
    "test_pred = pd.DataFrame(pred_array_test, columns=['predicted_rating_nb_ls'])\n",
    "test_pred.to_csv('predicted_rating_nb_ls_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_rating_nb_ls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.657468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.437715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.557692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.287962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.336538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>3.888232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>3.145349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>3.797619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>3.377966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>3.958048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predicted_rating_nb_ls\n",
       "0                    3.657468\n",
       "1                    4.437715\n",
       "2                    3.557692\n",
       "3                    4.287962\n",
       "4                    4.336538\n",
       "...                       ...\n",
       "79995                3.888232\n",
       "79996                3.145349\n",
       "79997                3.797619\n",
       "79998                3.377966\n",
       "79999                3.958048\n",
       "\n",
       "[80000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_ls_ratings_train = pd.read_csv('predicted_rating_nb_ls_train.csv')\n",
    "nb_ls_ratings_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_rating_nb_ls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.849673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.369841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.343739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.666804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>4.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>4.182927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2.993351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predicted_rating_nb_ls\n",
       "0                    2.849673\n",
       "1                    3.369841\n",
       "2                    3.343739\n",
       "3                    3.333333\n",
       "4                    3.666804\n",
       "...                       ...\n",
       "19995                4.035714\n",
       "19996                3.805029\n",
       "19997                4.182927\n",
       "19998                2.993351\n",
       "19999                3.900000\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_ls_ratings_test = pd.read_csv('predicted_rating_nb_ls_test.csv')\n",
    "nb_ls_ratings_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
